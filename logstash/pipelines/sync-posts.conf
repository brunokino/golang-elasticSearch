input {
    jdbc {
        jdbc_connection_string => "jdbc:postgresql://${POSTGRES_HOST}:5432/${POSTGRES_DB}"
        jdbc_user => "${POSTGRES_USER}"
        jdbc_password => "${POSTGRES_PASSWORD}"
        jdbc_driver_library => "/opt/logstash/vendor/jdbc/postgresql-42.2.18.jar"
        jdbc_driver_class => "org.postgresql.Driver"
        statement_filepath => "/usr/share/logstash/config/queries/sync-posts.sql"
        use_column_value => true
        tracking_column => "id"
        tracking_column_type => "numeric"
        schedule => "*/5 * * * * *"
    }
}

filter {
    if [operation] == "insert" or [operation] == "update" {
        mutate { add_field => { "[@metadata][action]" => "index" } }
      } else if [operation] == "delete" {
        mutate { add_field => { "[@metadata][action]" => "delete" }
    }
}

mutate {
# remove unneeded fields including ones that were added by logstash
    remove_field => ["@version", "@timestamp", "operation"]
  }
}

output {
    elasticsearch {
        hosts => ["http://elasticsearch:9200"] # URL of the ES docker container - docker would resolve it for us.
        action => "%{[@metadata][action]}"
        index => "posts"
        document_type => "post"
        document_id => "%{id}"
    }
}
